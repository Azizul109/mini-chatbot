import { Injectable, Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import { OpenAI } from 'openai';
import { OllamaProvider } from './ollama.provider';

export interface LLMResponse {
  content: string;
  tokensUsed: number;
}

export interface LLMProvider {
  generateCompletion(messages: any[], temperature?: number): Promise<LLMResponse>;
}

@Injectable()
export class OpenAIProvider implements LLMProvider {
  private readonly logger = new Logger(OpenAIProvider.name);
  private openai: OpenAI;

  constructor(private configService: ConfigService) {
    const apiKey = this.configService.get('OPENAI_API_KEY');
    
    if (!apiKey) {
      this.logger.warn('OpenAI API key not configured');
    } else {
      this.openai = new OpenAI({ apiKey });
      this.logger.log('OpenAI client initialized');
    }
  }

  async generateCompletion(messages: any[], temperature = 0.3): Promise<LLMResponse> {
    if (!this.openai) {
      throw new Error('OpenAI provider not configured');
    }

    try {
      this.logger.log('Sending request to OpenAI API...');
      
      const completion = await this.openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages,
        temperature,
        max_tokens: 1000,
      });

      this.logger.log('OpenAI response received successfully');

      return {
        content: completion.choices[0]?.message?.content || '',
        tokensUsed: completion.usage?.total_tokens || 0,
      };
    } catch (error: any) {
      this.logger.error('OpenAI API error:', error.message);
      throw new Error(`OpenAI API failed: ${error.message}`);
    }
  }
}

@Injectable()
export class MockLLMProvider implements LLMProvider {
  private readonly logger = new Logger(MockLLMProvider.name);

  async generateCompletion(messages: any[], temperature = 0.3): Promise<LLMResponse> {
    this.logger.log('Using mock LLM provider');
    
    await new Promise(resolve => setTimeout(resolve, 100));
    
    const lastMessage = messages[messages.length - 1]?.content || '';
    
    let response = '';
    if (lastMessage.toLowerCase().includes('shipping')) {
      response = 'Based on our shipping policy, we offer standard (3-5 days), express (1-2 days), and overnight shipping options. Standard shipping is free on orders over $50.';
    } else if (lastMessage.toLowerCase().includes('return')) {
      response = 'Our return policy allows returns within 30 days of purchase. Items must be in original condition with tags attached. Refunds are processed within 5-7 business days.';
    } else if (lastMessage.toLowerCase().includes('contact')) {
      response = 'You can contact our customer service team at 1-800-123-4567 or email support@company.com. We\'re available Monday-Friday 9AM-6PM EST.';
    } else {
      response = `This is a mock response to: "${lastMessage}". In production, this would be generated by the actual AI model.`;
    }

    return {
      content: response,
      tokensUsed: Math.floor(response.length / 4) + 50,
    };
  }
}

export const LLM_PROVIDERS = {
  openai: OpenAIProvider,
  ollama: OllamaProvider,
  mock: MockLLMProvider,
};